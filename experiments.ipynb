{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.stats import laplace, norm, t\n",
    "import scipy\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "VARIANCE = 2.0\n",
    "\n",
    "normal_scale = math.sqrt(VARIANCE)\n",
    "student_t_df = (2 * VARIANCE) / (VARIANCE - 1)\n",
    "laplace_scale = VARIANCE / 2\n",
    "\n",
    "HYPOTHESIS_SPACE = [norm(loc=0.0, scale=math.sqrt(VARIANCE)),\n",
    "                    laplace(loc=0.0, scale=laplace_scale),\n",
    "                    t(df=student_t_df)]\n",
    "\n",
    "PRIOR_PROBS = np.array([0.35, 0.25, 0.4])\n",
    "\n",
    "\n",
    "def generate_sample(n_samples, seed=None):\n",
    "    \"\"\" data generating process of the Bayesian model \"\"\"\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    hypothesis_idx = np.random.choice(3, p=PRIOR_PROBS)\n",
    "    dist = HYPOTHESIS_SPACE[hypothesis_idx]\n",
    "    return dist.rvs(n_samples, random_state=random_state)\n",
    "\n",
    "\n",
    "\"\"\" Solution \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def log_posterior_probs(x):\n",
    "    \"\"\"\n",
    "    Computes the log posterior probabilities for the three hypotheses, given the data x\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): one-dimensional numpy array containing the training data\n",
    "    Returns:\n",
    "        log_posterior_probs (np.ndarray): a numpy array of size 3, containing the Bayesian log-posterior probabilities\n",
    "                                          corresponding to the three hypotheses\n",
    "    \"\"\"\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    \n",
    "    for (dist,prior) in zip(HYPOTHESIS_SPACE,PRIOR_PROBS):\n",
    "        temp = dist.pdf(x)\n",
    "        # print(temp)\n",
    "        combined = np.sum(np.log(temp))\n",
    "        # print(combined)\n",
    "        withprior = combined + np.log(prior)\n",
    "        # print(\"withprior: \", withprior)\n",
    "        list1.append(withprior)\n",
    "\n",
    "\n",
    "    m = np.max(list1)\n",
    "    for logprob in list1:\n",
    "        # print(\"m: \", m)\n",
    "        # print(\"logprob: \", logprob)\n",
    "        # print(\"logprob-m: \", logprob-m)\n",
    "        shifted = logprob-m\n",
    "        # print(\"shifted: \", shifted)\n",
    "        converted = np.exp(shifted)\n",
    "        # print(\"converted: \", converted)\n",
    "        list2.append(converted)\n",
    "    \n",
    "    sum = np.array(list2).sum()\n",
    "\n",
    "    p = [list2[i]/sum for i in range(0,3)]\n",
    "    log_p = np.log(p)\n",
    "    return log_p\n",
    "\n",
    "\n",
    "def posterior_probs(x):\n",
    "    return np.exp(log_posterior_probs(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior probs for 1 sample from Laplacian\n",
      "Normal: 0.3239 , Laplace: 0.2441, Student-t: 0.4320\n",
      "\n",
      "Posterior probs for 50 samples from Laplacian\n",
      "Normal: 0.2550 , Laplace: 0.3388, Student-t: 0.4062\n",
      "\n",
      "Posterior probs for 1000 samples from Laplacian\n",
      "Normal: 0.0000 , Laplace: 1.0000, Student-t: 0.0000\n",
      "\n",
      "Posterior for 100 samples from the Bayesian data generating process\n",
      "Normal: 0.9735 , Laplace: 0.0023, Student-t: 0.0242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" sample from Laplace dist \"\"\"\n",
    "dist = HYPOTHESIS_SPACE[1]\n",
    "x = dist.rvs(1000, random_state=28)\n",
    "\n",
    "print(\"Posterior probs for 1 sample from Laplacian\")\n",
    "p = posterior_probs(x[:1])\n",
    "print(\"Normal: %.4f , Laplace: %.4f, Student-t: %.4f\\n\" % tuple(p))\n",
    "\n",
    "print(\"Posterior probs for 50 samples from Laplacian\")\n",
    "p = posterior_probs(x[:50])\n",
    "print(\"Normal: %.4f , Laplace: %.4f, Student-t: %.4f\\n\" % tuple(p))\n",
    "\n",
    "print(\"Posterior probs for 1000 samples from Laplacian\")\n",
    "p = posterior_probs(x[:1000])\n",
    "print(\"Normal: %.4f , Laplace: %.4f, Student-t: %.4f\\n\" % tuple(p))\n",
    "\n",
    "print(\"Posterior for 100 samples from the Bayesian data generating process\")\n",
    "x = generate_sample(n_samples=100)\n",
    "p = posterior_probs(x)\n",
    "print(\"Normal: %.4f , Laplace: %.4f, Student-t: %.4f\\n\" % tuple(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
