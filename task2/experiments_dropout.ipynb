{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import trange\n",
    "import tqdm\n",
    "from torch.distributions import Poisson\n",
    "from collections import deque\n",
    "import copy\n",
    "\n",
    "from util import ece, ParameterDistribution, draw_reliability_diagram, draw_confidence_histogram, SGLD\n",
    "from enum import Enum\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Framework(object):\n",
    "    def __init__(self, dataset_train:torch.utils.data.Dataset, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Basic Framework for your bayesian neural network.\n",
    "        Other solutions like MC Dropout, Ensemble learning will based upon this.\n",
    "        \"\"\"\n",
    "        self.train_set = dataset_train\n",
    "        self.print_interval = 100 # number of batches until updated metrics are displayed during training\n",
    "\n",
    "    def train(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, data_loader: torch.utils.data.DataLoader) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class probabilities using your trained model.\n",
    "        This method should return an (num_samples, 10) NumPy float array\n",
    "        such that the second dimension sums up to 1 for each row.\n",
    "\n",
    "        :param data_loader: Data loader yielding the samples to predict on\n",
    "        :return: (num_samples, 10) NumPy float array where the second dimension sums up to 1 for each row\n",
    "        \"\"\"\n",
    "        probability_batches = []\n",
    "        \n",
    "        for batch_x, _ in tqdm.tqdm(data_loader):\n",
    "            current_probabilities = self.predict_probabilities(batch_x).detach().numpy()\n",
    "            probability_batches.append(current_probabilities)\n",
    "\n",
    "        output = np.concatenate(probability_batches, axis=0)\n",
    "        assert isinstance(output, np.ndarray)\n",
    "        assert output.ndim == 2 and output.shape[1] == 10\n",
    "        assert np.allclose(np.sum(output, axis=1), 1.0)\n",
    "        return output\n",
    "\n",
    "    def predict_probabilities(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model:Framework, eval_loader: torch.utils.data.DataLoader, data_dir: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Evaluate your model.\n",
    "    :param model: Trained model to evaluate\n",
    "    :param eval_loader: Data loader containing the training set for evaluation\n",
    "    :param data_dir: Data directory from which additional datasets are loaded\n",
    "    :param output_dir: Directory into which plots are saved\n",
    "    \"\"\"\n",
    "    print(\"evaulating\")\n",
    "    # Predict class probabilities on test data\n",
    "    predicted_probabilities = model.predict(eval_loader)\n",
    "    \n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    predicted_classes = np.argmax(predicted_probabilities, axis=1)\n",
    "    actual_classes = eval_loader.dataset.tensors[1].detach().numpy()\n",
    "    accuracy = np.mean((predicted_classes == actual_classes)) \n",
    "    ece_score = ece(predicted_probabilities, actual_classes)\n",
    "    print(f'Accuracy: {accuracy.item():.3f}, ECE score: {ece_score:.3f}')\n",
    "    score = accuracy.item()+3*(0.5-ece_score)\n",
    "    print(f'score: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(16, 3, 1)\n",
    "        self.conv2 = nn.LazyConv2d(32, 3, 1)\n",
    "        self.fc1 = nn.LazyLinear(128)\n",
    "        self.fc2 = nn.LazyLinear(10)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.dropout(x,training=True,p=0.5)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x,training=True,p=0.5)\n",
    "        x = self.fc2(x)\n",
    "        # output = self.softmax(x)\n",
    "        return x\n",
    "#     def __init__(self,\n",
    "#                 in_features: int, \n",
    "#                 out_features: int,\n",
    "#                 dropout_p=0,\n",
    "#                 dropout_at_eval=False\n",
    "#                 ):\n",
    "#         super().__init__()\n",
    "#         # TODO General_2: Play around with the network structure.\n",
    "#         # You could change the depth or width of the model\n",
    "#         self.layer1 = nn.Linear(in_features,200)\n",
    "#         self.layer2 = nn.Linear(200, 200)\n",
    "#         self.layer3 = nn.Linear(200, out_features)\n",
    "#         self.dropout_p = dropout_p\n",
    "#         self.dropout_at_eval = dropout_at_eval\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # TODO General_2: Play around with the network structure\n",
    "#         # You might add different modules like Pooling \n",
    "#         x = F.dropout(\n",
    "#                 F.relu(self.layer1(x)),\n",
    "#                 p=self.dropout_p,\n",
    "#                 training=self.training or self.dropout_at_eval\n",
    "#         )\n",
    "#         x = F.dropout(\n",
    "#                 F.relu(self.layer2(x)),\n",
    "#                 p=self.dropout_p,\n",
    "#                 training=self.training or self.dropout_at_eval\n",
    "#         )\n",
    "\n",
    "#         class_probs = self.layer3(x)\n",
    "#         return class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DropoutTrainer(Framework):\n",
    "    def __init__(self, dataset_train,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(dataset_train, *args, **kwargs)\n",
    "\n",
    "        # Hyperparameters and general parameters\n",
    "        # TODO: MC_Dropout_4. Do experiments and tune hyperparameters\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 1e-3\n",
    "        self.num_epochs = 50\n",
    "        torch.manual_seed(0) # set seed for reproducibility\n",
    "        \n",
    "        # TODO: MC_Dropout_1. Initialize the MC_Dropout network and optimizer here\n",
    "        # You can check the Dummy Trainer above for intuition about what to do\n",
    "        self.network = MNISTNet()\n",
    "        self.train_loader = DataLoader(\n",
    "            dataset_train, batch_size=self.batch_size, shuffle=True, drop_last=True\n",
    "            )\n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr=self.learning_rate) \n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        self.network.train()\n",
    "        self.network  = self.network.to(\"cuda\")\n",
    "        # self.train_loader  = self.train_loader.to(\"cuda\")\n",
    "        progress_bar = trange(self.num_epochs)\n",
    "        for _ in progress_bar:\n",
    "            for batch_idx, (batch_x, batch_y) in enumerate(self.train_loader):\n",
    "                # batch_x are of shape (batch_size, 784), batch_y are of shape (batch_size,)\n",
    "\n",
    "                batch_x = batch_x.to(\"cuda\").view(-1,1,28,28)\n",
    "                batch_y = batch_y.to(\"cuda\")\n",
    "\n",
    "                self.network.zero_grad()\n",
    "                # TODO: MC_Dropout_2. Implement MCDropout training here\n",
    "                # You need to calculate the loss based on the literature\n",
    "                preds = F.softmax(self.network(batch_x),dim=-1)\n",
    "                loss = F.nll_loss(preds,batch_y)\n",
    "                # preds = preds.cpu()\n",
    "                # batch_y = batch_y.cpu()\n",
    "                # ece_ = ece(preds,batch_y)\n",
    "                # ece_ = ece_.to(\"cuda\")\n",
    "\n",
    "                # loss = loss + ece_\n",
    "                # loss = F.nll_loss(preds,batch_y)\n",
    "\n",
    "                # Backpropagate to get the gradients\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "                # Update progress bar with accuracy occasionally\n",
    "                if batch_idx % self.print_interval == 0:\n",
    "                    current_logits = self.network(batch_x)\n",
    "                    current_accuracy = (current_logits.argmax(axis=1) == batch_y).float().mean()\n",
    "                    progress_bar.set_postfix(loss=loss.item(), acc=current_accuracy.item())\n",
    "          \n",
    "\n",
    "    def predict_probabilities(self, x: torch.Tensor, num_sample=100) -> torch.Tensor:\n",
    "        assert x.shape[1] == 28 ** 2\n",
    "        self.network.eval()\n",
    "\n",
    "        x = x.to(\"cuda\").view(-1,1,28,28)\n",
    "        # TODO: MC_Dropout_3. Implement your MC_dropout prediction here\n",
    "        # You need to sample from your trained model here multiple times\n",
    "        # in order to implement Monte Carlo integration\n",
    "        preds = []\n",
    "        for i in range(10):\n",
    "            pred = self.network(x)\n",
    "            pred = F.softmax(pred,dim=-1)\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            preds.append(pred)\n",
    "\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        # print(\"preds shape\")\n",
    "        # print(preds.shape)\n",
    "        # print(preds)\n",
    "\n",
    "        estimated_probability = preds.mean(axis=0)\n",
    "\n",
    "        # print(\"estimated_probability shape\")\n",
    "        # print(estimated_probability.shape)\n",
    "        # print(estimated_probability[0])\n",
    "\n",
    "        estimated_probability = torch.from_numpy(estimated_probability)\n",
    "        \n",
    "        assert estimated_probability.shape == (x.shape[0], 10)  \n",
    "        return estimated_probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_solution(dataset_train: torch.utils.data.Dataset, data_dir: str = os.curdir, output_dir: str = '/results/'):\n",
    "    \"\"\"\n",
    "    Run your task 2 solution.\n",
    "    This method should train your model, evaluate it, and return the trained model at the end.\n",
    "    Make sure to preserve the method signature and to return your trained model,\n",
    "    else the checker will fail!\n",
    "\n",
    "    :param dataset_train: Training dataset\n",
    "    :param data_dir: Directory containing the datasets\n",
    "    :return: Your trained model\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    trainer = DropoutTrainer(dataset_train=dataset_train)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    print('Training model')\n",
    "    trainer.train()\n",
    "\n",
    "    # Predict using the trained model\n",
    "    print('Evaluating model on training data')\n",
    "    eval_loader = torch.utils.data.DataLoader(\n",
    "        dataset_train, batch_size=64, shuffle=False, drop_last=False\n",
    "    )\n",
    "    evaluate(trainer, eval_loader, data_dir, output_dir)\n",
    "\n",
    "    # IMPORTANT: return your model here!\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 28, 28)\n",
      "Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:28<00:00,  1.77it/s, acc=0.984, loss=-.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on training data\n",
      "evaulating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 106.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991, ECE score: 0.009\n",
      "score: 2.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "data_dir = os.curdir\n",
    "output_dir = os.curdir\n",
    "raw_train_data = np.load(os.path.join(data_dir, 'train_data.npz'))\n",
    "print(raw_train_data['train_x'].shape)\n",
    "x_train = torch.from_numpy(raw_train_data['train_x']).reshape([-1, 784])\n",
    "y_train = torch.from_numpy(raw_train_data['train_y']).long()\n",
    "dataset_train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "\n",
    "# Run actual solution\n",
    "trainer = run_solution(dataset_train, data_dir=data_dir, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.network = trainer.network.cpu()\n",
    "torch.save(trainer.network.state_dict(),\"trainer.pth\")\n",
    "# torch.save(trainer.state_dict(), 'trainer.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
